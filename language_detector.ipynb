{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "language_detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y-94q19AT1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b0cbb37-7b42-41c7-95ed-af53d31dd68d"
      },
      "source": [
        "!pip install allennlp\n",
        "!git clone https://github.com/mhagiwara/realworldnlp.git\n",
        "%cd realworldnlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 8.4MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d8/5e877ac5e827eaa41a7ea8c0dc1d3042e05d7e337604dc2aedb854e7b500/ftfy-5.7.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Collecting flask-cors>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/6b/fbb2d499b96861a18c1641f6fefe775110d3faba65c1524950e9ad64824a/jsonpickle-1.3-py2.py3-none-any.whl\n",
            "Collecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/52/8063322bd9ee6e7921b74fcb730c6ba983ff995ddfabd966bb689e313464/responses-0.10.12-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Collecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.9)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/b8/a8588d4010f13716a324f55d23999259bad9db2320f4fe919a66b2f651f3/jsonnet-0.15.0.tar.gz (255kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 39.7MB/s \n",
            "\u001b[?25hCollecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 68.8MB/s \n",
            "\u001b[?25hCollecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.17.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.11.15)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Collecting conllu==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 67.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Collecting numpydoc>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/70/4d8c3f9f6783a57ac9cc7a076e5610c0cc4a96af543cafc9247ac307fbfe/numpydoc-0.9.2.tar.gz\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Collecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/72/dd/ac49f9c69540d7e09210415801a05d0a54d4d0ca8401503c46847dacd3a0/overrides-2.8.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.8)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.6/dist-packages (from flask-cors>=3.0.7->allennlp) (1.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 61.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.6.0)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.14.15)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.11.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.0.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (45.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->allennlp) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp) (1.1.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.8.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (20.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Building wheels for collected packages: ftfy, jsonnet, parsimonious, word2number, numpydoc, overrides\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.7-cp36-none-any.whl size=44593 sha256=e6b4062a23d6a529ddc73ab1485907612e6e4f3613dd181d71b9f9d4b27c7d2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/da/59/6c8925d571aacade638a0f515960c21c0887af1bfe31908fbf\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.15.0-cp36-cp36m-linux_x86_64.whl size=3320540 sha256=3ef8c74d22f27f3ab8e4f923fa99b80ba31e6bbad9a45178d66dc7cd05472cd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/63/2e/da89cfe1ba08550bd7262d5d9c027edc313980c3b85b3b0a38\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42712 sha256=a9929f4b7e9d8cf59d5b1edefb8bf47ca3d709f6f19be9f02e1a829c3e245d7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5587 sha256=ab4eeeaa8b7f2b6c361bb1c5f8a7c8cf3c0409b2f558b2ef18a8932263c96f19\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.9.2-cp36-none-any.whl size=31893 sha256=e23d7931e6d9d5054fa6f6f878d5c2a995f41154852719a3fb15cd8a66f024ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/f3/52/25c8e1f40637661d27feebc61dae16b84c7cdd93b8bc3d7486\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.8.0-cp36-none-any.whl size=5609 sha256=08f5b9cd61ea683277e48650bfb15627a28cd1b89dd1a132e8d6604fc088d0e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/f1/ba/eaf6cd7d284d2f257dc71436ce72d25fd3be5a5813a37794ab\n",
            "Successfully built ftfy jsonnet parsimonious word2number numpydoc overrides\n",
            "Installing collected packages: ftfy, flask-cors, jsonpickle, responses, sentencepiece, pytorch-transformers, jsonnet, parsimonious, word2number, pytorch-pretrained-bert, flaky, unidecode, conllu, tensorboardX, numpydoc, overrides, allennlp\n",
            "Successfully installed allennlp-0.9.0 conllu-1.3.1 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.7 jsonnet-0.15.0 jsonpickle-1.3 numpydoc-0.9.2 overrides-2.8.0 parsimonious-0.8.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.10.12 sentencepiece-0.1.85 tensorboardX-2.0 unidecode-1.1.1 word2number-1.1\n",
            "Cloning into 'realworldnlp'...\n",
            "remote: Enumerating objects: 479, done.\u001b[K\n",
            "remote: Total 479 (delta 0), reused 0 (delta 0), pack-reused 479\u001b[K\n",
            "Receiving objects: 100% (479/479), 4.69 MiB | 7.36 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n",
            "/content/realworldnlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJF_dMjIAT1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from allennlp.common.file_utils import cached_path\n",
        "from allennlp.data.dataset_readers import DatasetReader\n",
        "from allennlp.data.fields import LabelField, TextField\n",
        "from allennlp.data.instance import Instance\n",
        "from allennlp.data.iterators import BucketIterator\n",
        "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
        "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.training.trainer import Trainer\n",
        "from overrides import overrides\n",
        "\n",
        "from examples.sentiment.sst_classifier import LstmClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEFS0bkIAT1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 16\n",
        "HIDDEN_DIM = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuR7lCsrAT19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TatoebaSentenceReader(DatasetReader):\n",
        "    def __init__(self, token_indexers: Dict[str, TokenIndexer]=None, lazy=False):\n",
        "        super().__init__(lazy=lazy)\n",
        "        self.tokenizer = CharacterTokenizer()\n",
        "        self.token_indexers = token_indexers or {'tokens': SingleIdTokenIndexer()}\n",
        "\n",
        "    @overrides\n",
        "    def text_to_instance(self, tokens, label=None):\n",
        "        fields = {}\n",
        "\n",
        "        fields['tokens'] = TextField(tokens, self.token_indexers)\n",
        "        if label:\n",
        "            fields['label'] = LabelField(label)\n",
        "\n",
        "        return Instance(fields)\n",
        "\n",
        "    @overrides\n",
        "    def _read(self, file_path: str):\n",
        "        file_path = cached_path(file_path)\n",
        "        with open(file_path, \"r\") as text_file:\n",
        "            for line in text_file:\n",
        "                lang_id, sent = line.rstrip().split('\\t')\n",
        "\n",
        "                tokens = self.tokenizer.tokenize(sent)\n",
        "\n",
        "                yield self.text_to_instance(tokens, lang_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUotwmiMAT2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(text: str, model: LstmClassifier):\n",
        "    tokenizer = CharacterTokenizer()\n",
        "    token_indexers = {'tokens': SingleIdTokenIndexer()}\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    instance = Instance({'tokens': TextField(tokens, token_indexers)})\n",
        "    logits = model.forward_on_instance(instance)['logits']\n",
        "    label_id = np.argmax(logits)\n",
        "    label = model.vocab.get_token_from_index(label_id, 'labels')\n",
        "\n",
        "    print('text: {}, label: {}'.format(text, label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efyTZ4NTAT2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reader = TatoebaSentenceReader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52GO7JVyAT2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "b89acca2-a1d5-4605-d6f3-0f38d6e0a348"
      },
      "source": [
        "train_set = reader.read('https://s3.amazonaws.com/realworldnlpbook/data/tatoeba/sentences.top10langs.train.tsv')\n",
        "dev_set = reader.read('https://s3.amazonaws.com/realworldnlpbook/data/tatoeba/sentences.top10langs.dev.tsv')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "  0%|          | 0/4414160 [00:00<?, ?B/s]\u001b[A\n",
            "  1%|          | 52224/4414160 [00:00<00:13, 312595.29B/s]\u001b[A\n",
            "  6%|▌         | 243712/4414160 [00:00<00:10, 399021.79B/s]\u001b[A\n",
            " 21%|██        | 922624/4414160 [00:00<00:06, 546638.44B/s]\u001b[A\n",
            " 60%|██████    | 2667520/4414160 [00:00<00:02, 763476.15B/s]\u001b[A\n",
            "100000it [00:09, 10486.73it/s]\n",
            "0it [00:00, ?it/s]\n",
            "  0%|          | 0/443237 [00:00<?, ?B/s]\u001b[A\n",
            " 12%|█▏        | 52224/443237 [00:00<00:01, 329353.31B/s]\u001b[A\n",
            " 55%|█████▍    | 243712/443237 [00:00<00:00, 417511.09B/s]\u001b[A\n",
            "10000it [00:01, 6148.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO_vVxVoAT2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e47e788b-7d69-429c-de5b-7e88d224ffc4"
      },
      "source": [
        "vocab = Vocabulary.from_instances(train_set,\n",
        "                                  min_count={'tokens': 3})"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:01<00:00, 58096.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eXZl_r5AT22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
        "                            embedding_dim=EMBEDDING_DIM)\n",
        "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOC44ZSkAT3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = PytorchSeq2VecWrapper(\n",
        "    torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAV22JYRAT3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LstmClassifier(word_embeddings, encoder, vocab, positive_label='eng')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDCskb0tAT3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterator = BucketIterator(batch_size=32, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kwAYqL1AT3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GfSa9jtAT3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = Trainer(model=model,\n",
        "                  optimizer=optimizer,\n",
        "                  iterator=iterator,\n",
        "                  train_dataset=train_set,\n",
        "                  validation_dataset=dev_set,\n",
        "                  num_epochs=10)\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up_NnB4ZAT3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "699f0d31-0054-403f-c9af-8e3c75157e07"
      },
      "source": [
        "classify('Take your raincoat in case it rains.', model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Take your raincoat in case it rains., label: eng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht72IZtzAT35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "977351c1-add0-49ce-96ae-c5fc312f5136"
      },
      "source": [
        "classify('Tu me recuerdas a mi padre.', model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Tu me recuerdas a mi padre., label: spa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg9EE3QiAT4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d72419de-c417-4791-dd04-c77055c5b503"
      },
      "source": [
        "classify('Wie organisierst du das Essen am Mittag?', model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Wie organisierst du das Essen am Mittag?, label: deu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfN7y0xcAT4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27ccd43f-7b8c-459a-f672-1b6c166226b4"
      },
      "source": [
        "classify(\"Il est des cas où cette règle ne s'applique pas.\", model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Il est des cas où cette règle ne s'applique pas., label: fra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8cV8_w2AT4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87f79de1-7ed8-48ef-b526-1a347be5afb6"
      },
      "source": [
        "classify('Estou fazendo um passeio em um parque.', model)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Estou fazendo um passeio em um parque., label: por\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIeR_ecoAT4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0922673-8fa0-4895-b53b-6485907966d5"
      },
      "source": [
        "classify('Ve, postmorgaŭ jam estas la limdato.', model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Ve, postmorgaŭ jam estas la limdato., label: epo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sceT2od2AT4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ca8a082-9048-4552-ea4b-a97d38d022c1"
      },
      "source": [
        "classify('Credevo che sarebbe venuto.', model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Credevo che sarebbe venuto., label: ita\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRX0w2seAT42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3811e192-8f57-4874-cf23-b28805a42338"
      },
      "source": [
        "classify('Nem tudja, hogy én egy macska vagyok.', model)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Nem tudja, hogy én egy macska vagyok., label: hun\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bESearKTAT5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd96e826-da38-40e2-c43d-42d0d4007f1d"
      },
      "source": [
        "classify('Nella ur nli qrib acemma deg tenwalt.', model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Nella ur nli qrib acemma deg tenwalt., label: ber\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n821_VhAT5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07eee0b8-68d3-4744-dd0c-473cceb0317d"
      },
      "source": [
        "classify('Kurşun kalemin yok, değil mi?', model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Kurşun kalemin yok, değil mi?, label: tur\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt3aoHG_AT5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}